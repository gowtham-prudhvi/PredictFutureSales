{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nfrom itertools import product\n\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndef downcast_dtypes(df):\n    '''\n        Changes column types in the dataframe: \n                \n                `float64` type to `float32`\n                `int64`   type to `int32`\n    '''\n    \n    # Select columns to downcast\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n    \n    # Downcast\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols]   = df[int_cols].astype(np.int32)\n    \n    return df\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\n/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\n/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\n/kaggle/input/competitive-data-science-predict-future-sales/items.csv\n/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\n/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\nitem_categories = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitems = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nsales_train = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nsample_submission = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nshops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\ntest = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")\ntest","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"            ID  shop_id  item_id\n0            0        5     5037\n1            1        5     5320\n2            2        5     5233\n3            3        5     5232\n4            4        5     5268\n...        ...      ...      ...\n214195  214195       45    18454\n214196  214196       45    16188\n214197  214197       45    15757\n214198  214198       45    19648\n214199  214199       45      969\n\n[214200 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>shop_id</th>\n      <th>item_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5</td>\n      <td>5037</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>5</td>\n      <td>5320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>5233</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>5</td>\n      <td>5232</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5</td>\n      <td>5268</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>214195</th>\n      <td>214195</td>\n      <td>45</td>\n      <td>18454</td>\n    </tr>\n    <tr>\n      <th>214196</th>\n      <td>214196</td>\n      <td>45</td>\n      <td>16188</td>\n    </tr>\n    <tr>\n      <th>214197</th>\n      <td>214197</td>\n      <td>45</td>\n      <td>15757</td>\n    </tr>\n    <tr>\n      <th>214198</th>\n      <td>214198</td>\n      <td>45</td>\n      <td>19648</td>\n    </tr>\n    <tr>\n      <th>214199</th>\n      <td>214199</td>\n      <td>45</td>\n      <td>969</td>\n    </tr>\n  </tbody>\n</table>\n<p>214200 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oct_trans=sales_train[sales_train[\"date\"].str.endswith(\"10.2015\")]\noct_sales = oct_trans.groupby(['shop_id','item_id'])['item_cnt_day'].sum()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nov_trans=sales_train[sales_train[\"date\"].str.endswith(\"11.2014\")]\nnov_sales = nov_trans.groupby(['shop_id','item_id'])['item_cnt_day'].sum()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged=pd.merge(test,oct_sales,on=['shop_id','item_id'],how=\"outer\")\n#merged=merged[merged['ID']!=np.nan]\nmerged=merged.dropna(subset=['ID'])\nmerged=merged.replace(np.nan,0)\nmerged['item_cnt_month']=merged['item_cnt_day'].clip(lower=0,upper=20)\nmerged=merged.drop(['shop_id','item_id','item_cnt_day'],axis=1)\nmerged['ID']=merged['ID'].astype('int')\nmerged.to_csv(\"october_sales.csv\",index=False)\nmerged\n# print(merged.shape)\n# sample_submission.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"            ID  item_cnt_month\n0            0             0.0\n1            1             0.0\n2            2             1.0\n3            3             0.0\n4            4             0.0\n...        ...             ...\n214195  214195             1.0\n214196  214196             0.0\n214197  214197             0.0\n214198  214198             0.0\n214199  214199             0.0\n\n[214200 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>item_cnt_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>214195</th>\n      <td>214195</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>214196</th>\n      <td>214196</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>214197</th>\n      <td>214197</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>214198</th>\n      <td>214198</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>214199</th>\n      <td>214199</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>214200 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = sales_train\n\n# Create \"grid\" with columns\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\n\n# For every month we create a grid from all shops/items combinations from that month\ngrid = [] \nfor block_num in sales['date_block_num'].unique():\n    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n\n# Turn the grid into a dataframe\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n\n# Groupby data to get shop-item-month aggregates\ngb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n# Fix column names\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n# Join it to the grid\nall_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n\n# Same as above but with shop-month aggregates\ngb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\nall_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n\n# Same as above but with item-month aggregates\ngb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\ngb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\nall_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n\n# Downcast dtypes from 64 to 32 bit to save memory\nall_data = downcast_dtypes(all_data)\ndel grid, gb \ngc.collect();","execution_count":6,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\nin a future version.\n\nFor column-specific groupby renaming, use named aggregation\n\n    >>> df.groupby(...).agg(name=('column', aggfunc))\n\n  return super().aggregate(arg, *args, **kwargs)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of columns that we will use to create lags\ncols_to_rename = list(all_data.columns.difference(index_cols)) \n\nshift_range = [1, 2, 3, 4, 5, 12]\n\nfor month_shift in tqdm_notebook(shift_range):\n    train_shift = all_data[index_cols + cols_to_rename].copy()\n    \n    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n    \n    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n    train_shift = train_shift.rename(columns=foo)\n\n    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n\ndel train_shift\n\n# Don't use old data from year 2013\nall_data = all_data[all_data['date_block_num'] >= 12] \n\n# List of all lagged features\nfit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n# We will drop these at fitting stage\nto_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n\n# Category for each item\nitem_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n\nall_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\nall_data = downcast_dtypes(all_data)\ngc.collect();","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=6), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a10ff1fbcf24902883d5924fb7dd672"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(all_data)","execution_count":8,"outputs":[{"output_type":"stream","text":"         shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n0             54    10297              12     4.0       8198.0         23.0   \n1             54    10296              12     3.0       8198.0         17.0   \n2             54    10298              12    14.0       8198.0        182.0   \n3             54    10300              12     3.0       8198.0         26.0   \n4             54    10284              12     1.0       8198.0          3.0   \n...          ...      ...             ...     ...          ...          ...   \n6425089       21     7635              33     0.0       1912.0          1.0   \n6425090       21     7638              33     0.0       1912.0          1.0   \n6425091       21     7640              33     0.0       1912.0          1.0   \n6425092       21     7632              33     0.0       1912.0          1.0   \n6425093       21     7440              33     0.0       1912.0          1.0   \n\n         target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n0                 3.0               42.0            10055.0           0.0   \n1                 0.0               24.0            10055.0           0.0   \n2                21.0              369.0            10055.0         119.0   \n3                 1.0               54.0            10055.0          31.0   \n4                 0.0                4.0            10055.0           0.0   \n...               ...                ...                ...           ...   \n6425089           0.0                0.0                0.0           0.0   \n6425090           0.0                0.0                0.0           0.0   \n6425091           0.0                0.0                0.0           0.0   \n6425092           0.0                1.0             1900.0           0.0   \n6425093           0.0                1.0             1900.0           0.0   \n\n         ...  target_lag_4  target_item_lag_4  target_shop_lag_4  \\\n0        ...           0.0                0.0                0.0   \n1        ...           0.0                0.0                0.0   \n2        ...           0.0                0.0                0.0   \n3        ...           0.0                0.0                0.0   \n4        ...           0.0                3.0             7827.0   \n...      ...           ...                ...                ...   \n6425089  ...           0.0                0.0                0.0   \n6425090  ...           0.0                0.0                0.0   \n6425091  ...           0.0                0.0                0.0   \n6425092  ...           0.0                0.0                0.0   \n6425093  ...           0.0                2.0             1844.0   \n\n         target_lag_5  target_item_lag_5  target_shop_lag_5  target_lag_12  \\\n0                 0.0                0.0                0.0            0.0   \n1                 0.0                0.0                0.0            0.0   \n2                 0.0                0.0                0.0            0.0   \n3                 0.0                0.0                0.0            0.0   \n4                 0.0               10.0             7792.0            0.0   \n...               ...                ...                ...            ...   \n6425089           0.0                0.0                0.0            0.0   \n6425090           0.0                0.0                0.0            0.0   \n6425091           0.0                0.0                0.0            0.0   \n6425092           0.0                0.0                0.0            0.0   \n6425093           0.0                4.0             1717.0            0.0   \n\n         target_item_lag_12  target_shop_lag_12  item_category_id  \n0                       0.0                 0.0                37  \n1                       0.0                 0.0                38  \n2                       0.0                 0.0                40  \n3                       0.0                 0.0                37  \n4                       0.0                 0.0                57  \n...                     ...                 ...               ...  \n6425089                 0.0                 0.0                64  \n6425090                 0.0                 0.0                64  \n6425091                 0.0                 0.0                64  \n6425092                 0.0                 0.0                64  \n6425093                 0.0                 0.0                57  \n\n[6425094 rows x 25 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"dates = all_data['date_block_num']\n\nlast_block = dates.max()\nprint(last_block)\nX_train = all_data.loc[dates <=  last_block].drop(to_drop_cols, axis=1)\n#print(X_train.head)\nX_test =  all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n#print(X_test.head)\n\ny_train = all_data.loc[dates <  last_block, 'target'].values\ny_test =  all_data.loc[dates == last_block, 'target'].values","execution_count":11,"outputs":[{"output_type":"stream","text":"33\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of columns that we will use to create lags\ncols_to_rename = list(all_data.columns.difference(index_cols)) \n\nshift_range = [1, 2, 3, 4, 5, 12]\n\nfor month_shift in tqdm_notebook(shift_range):\n    test_shift = test.copy()\n    \n    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n    \n    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n    train_shift = train_shift.rename(columns=foo)\n\n    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n\ndel train_shift\n\n# Don't use old data from year 2013\nall_data = all_data[all_data['date_block_num'] >= 12] \n\n# List of all lagged features\nfit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n# We will drop these at fitting stage\nto_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n\n# Category for each item\nitem_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n\nall_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\nall_data = downcast_dtypes(all_data)\ngc.collect();","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}