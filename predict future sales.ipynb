{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\nfrom itertools import product\n\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def downcast_dtypes(df):\n    '''\n        Changes column types in the dataframe: \n                \n                `float64` type to `float32`\n                `int64`   type to `int32`\n    '''\n    \n    # Select columns to downcast\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n    \n    # Downcast\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols]   = df[int_cols].astype(np.int32)\n    \n    return df\n","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"item_categories = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitems = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\nsales_train = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\nsample_submission = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nshops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\ntest = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sales_train.head())\nprint(test.head())\nprint(items.head())","execution_count":13,"outputs":[{"output_type":"stream","text":"         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n0  02.01.2013               0       59    22154      999.00           1.0\n1  03.01.2013               0       25     2552      899.00           1.0\n2  05.01.2013               0       25     2552      899.00          -1.0\n3  06.01.2013               0       25     2554     1709.05           1.0\n4  15.01.2013               0       25     2555     1099.00           1.0\n   ID  shop_id  item_id\n0   0        5     5037\n1   1        5     5320\n2   2        5     5233\n3   3        5     5232\n4   4        5     5268\n                                           item_name  item_id  \\\n0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n1  !ABBYY FineReader 12 Professional Edition Full...        1   \n2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n4        ***КОРОБКА (СТЕКЛО)                       D        4   \n\n   item_category_id  \n0                40  \n1                76  \n2                40  \n3                40  \n4                40  \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_temp = test.copy()\ntest_temp['date_block_num'] = 34\nitem_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\ntest_temp = pd.merge(test_temp, item_category_mapping, how='left', on='item_id')\ntest_temp = test_temp.drop('ID',axis = 1)\nsales_train = sales_train.drop('date', axis = 1)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_temp\nsales_train_full = pd.concat([sales_train,test_temp], ignore_index = True)","execution_count":25,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  \n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_full","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"         date_block_num  item_category_id  item_cnt_day  item_id  item_price  \\\n0                     0               NaN           1.0    22154      999.00   \n1                     0               NaN           1.0     2552      899.00   \n2                     0               NaN          -1.0     2552      899.00   \n3                     0               NaN           1.0     2554     1709.05   \n4                     0               NaN           1.0     2555     1099.00   \n...                 ...               ...           ...      ...         ...   \n3150044              34              55.0           NaN    18454         NaN   \n3150045              34              64.0           NaN    16188         NaN   \n3150046              34              55.0           NaN    15757         NaN   \n3150047              34              40.0           NaN    19648         NaN   \n3150048              34              37.0           NaN      969         NaN   \n\n         shop_id  \n0             59  \n1             25  \n2             25  \n3             25  \n4             25  \n...          ...  \n3150044       45  \n3150045       45  \n3150046       45  \n3150047       45  \n3150048       45  \n\n[3150049 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_block_num</th>\n      <th>item_category_id</th>\n      <th>item_cnt_day</th>\n      <th>item_id</th>\n      <th>item_price</th>\n      <th>shop_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>22154</td>\n      <td>999.00</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2552</td>\n      <td>899.00</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>-1.0</td>\n      <td>2552</td>\n      <td>899.00</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2554</td>\n      <td>1709.05</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2555</td>\n      <td>1099.00</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3150044</th>\n      <td>34</td>\n      <td>55.0</td>\n      <td>NaN</td>\n      <td>18454</td>\n      <td>NaN</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3150045</th>\n      <td>34</td>\n      <td>64.0</td>\n      <td>NaN</td>\n      <td>16188</td>\n      <td>NaN</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3150046</th>\n      <td>34</td>\n      <td>55.0</td>\n      <td>NaN</td>\n      <td>15757</td>\n      <td>NaN</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3150047</th>\n      <td>34</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>19648</td>\n      <td>NaN</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>3150048</th>\n      <td>34</td>\n      <td>37.0</td>\n      <td>NaN</td>\n      <td>969</td>\n      <td>NaN</td>\n      <td>45</td>\n    </tr>\n  </tbody>\n</table>\n<p>3150049 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = sales_train_full\n\n# Create \"grid\" with columns\nindex_cols = ['shop_id', 'item_id', 'date_block_num']\n\n# For every month we create a grid from all shops/items combinations from that month\ngrid = [] \nfor block_num in sales['date_block_num'].unique():\n    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n\n# Turn the grid into a dataframe\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n\n# Groupby data to get shop-item-month aggregates\ngb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':{'target':'sum'}})\n# Fix column names\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values] \n# Join it to the grid\nall_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n\n# Same as above but with shop-month aggregates\ngb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_shop':'sum'}})\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\nall_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n\n# Same as above but with item-month aggregates\ngb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':{'target_item':'sum'}})\ngb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\nall_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n\n# Downcast dtypes from 64 to 32 bit to save memory\nall_data = downcast_dtypes(all_data)\n#all_data2 = all_data.copy()\ndel grid, gb \ngc.collect();","execution_count":27,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\nin a future version.\n\nFor column-specific groupby renaming, use named aggregation\n\n    >>> df.groupby(...).agg(name=('column', aggfunc))\n\n  return super().aggregate(arg, *args, **kwargs)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of columns that we will use to create lags\ncols_to_rename = list(all_data.columns.difference(index_cols)) \n\nshift_range = [1, 2, 3, 4, 5, 12]\n\nfor month_shift in tqdm_notebook(shift_range):\n    train_shift = all_data[index_cols + cols_to_rename].copy()\n    \n    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n    \n    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n    train_shift = train_shift.rename(columns=foo)\n\n    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n\ndel train_shift\n\n# Don't use old data from year 2013\nall_data = all_data[all_data['date_block_num'] >= 12] \n\n# List of all lagged features\nfit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n# We will drop these at fitting stage\nto_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n\n# Category for each item\nitem_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n\nall_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\nall_data = downcast_dtypes(all_data)\ngc.collect();","execution_count":28,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=6), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b51f9da9f03b4b58a7ccffc2d86530b9"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"         shop_id  item_id  date_block_num  target  target_shop  target_item  \\\n0             54    10297              12     4.0       8198.0         23.0   \n1             54    10296              12     3.0       8198.0         17.0   \n2             54    10298              12    14.0       8198.0        182.0   \n3             54    10300              12     3.0       8198.0         26.0   \n4             54    10284              12     1.0       8198.0          3.0   \n...          ...      ...             ...     ...          ...          ...   \n6639289       45    18454              34     0.0          0.0          0.0   \n6639290       45    16188              34     0.0          0.0          0.0   \n6639291       45    15757              34     0.0          0.0          0.0   \n6639292       45    19648              34     0.0          0.0          0.0   \n6639293       45      969              34     0.0          0.0          0.0   \n\n         target_lag_1  target_item_lag_1  target_shop_lag_1  target_lag_2  \\\n0                 3.0               42.0            10055.0           0.0   \n1                 0.0               24.0            10055.0           0.0   \n2                21.0              369.0            10055.0         119.0   \n3                 1.0               54.0            10055.0          31.0   \n4                 0.0                4.0            10055.0           0.0   \n...               ...                ...                ...           ...   \n6639289           1.0                2.0              702.0           0.0   \n6639290           0.0                1.0              702.0           0.0   \n6639291           0.0                5.0              702.0           0.0   \n6639292           0.0                2.0              702.0           0.0   \n6639293           0.0                3.0              702.0           0.0   \n\n         ...  target_lag_4  target_item_lag_4  target_shop_lag_4  \\\n0        ...           0.0                0.0                0.0   \n1        ...           0.0                0.0                0.0   \n2        ...           0.0                0.0                0.0   \n3        ...           0.0                0.0                0.0   \n4        ...           0.0                3.0             7827.0   \n...      ...           ...                ...                ...   \n6639289  ...           0.0               12.0              675.0   \n6639290  ...           0.0                0.0                0.0   \n6639291  ...           0.0                4.0              675.0   \n6639292  ...           0.0                2.0              675.0   \n6639293  ...           0.0                2.0              675.0   \n\n         target_lag_5  target_item_lag_5  target_shop_lag_5  target_lag_12  \\\n0                 0.0                0.0                0.0            0.0   \n1                 0.0                0.0                0.0            0.0   \n2                 0.0                0.0                0.0            0.0   \n3                 0.0                0.0                0.0            0.0   \n4                 0.0               10.0             7792.0            0.0   \n...               ...                ...                ...            ...   \n6639289           0.0               19.0              622.0            0.0   \n6639290           0.0                0.0                0.0            0.0   \n6639291           0.0                8.0              622.0            0.0   \n6639292           0.0                4.0              622.0            0.0   \n6639293           0.0                2.0              622.0            0.0   \n\n         target_item_lag_12  target_shop_lag_12  item_category_id  \n0                       0.0                 0.0                37  \n1                       0.0                 0.0                38  \n2                       0.0                 0.0                40  \n3                       0.0                 0.0                37  \n4                       0.0                 0.0                57  \n...                     ...                 ...               ...  \n6639289                 0.0                 0.0                55  \n6639290                 0.0                 0.0                64  \n6639291                 9.0              1251.0                55  \n6639292                 0.0                 0.0                40  \n6639293                 6.0              1251.0                37  \n\n[6639294 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>shop_id</th>\n      <th>item_id</th>\n      <th>date_block_num</th>\n      <th>target</th>\n      <th>target_shop</th>\n      <th>target_item</th>\n      <th>target_lag_1</th>\n      <th>target_item_lag_1</th>\n      <th>target_shop_lag_1</th>\n      <th>target_lag_2</th>\n      <th>...</th>\n      <th>target_lag_4</th>\n      <th>target_item_lag_4</th>\n      <th>target_shop_lag_4</th>\n      <th>target_lag_5</th>\n      <th>target_item_lag_5</th>\n      <th>target_shop_lag_5</th>\n      <th>target_lag_12</th>\n      <th>target_item_lag_12</th>\n      <th>target_shop_lag_12</th>\n      <th>item_category_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54</td>\n      <td>10297</td>\n      <td>12</td>\n      <td>4.0</td>\n      <td>8198.0</td>\n      <td>23.0</td>\n      <td>3.0</td>\n      <td>42.0</td>\n      <td>10055.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>54</td>\n      <td>10296</td>\n      <td>12</td>\n      <td>3.0</td>\n      <td>8198.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>10055.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54</td>\n      <td>10298</td>\n      <td>12</td>\n      <td>14.0</td>\n      <td>8198.0</td>\n      <td>182.0</td>\n      <td>21.0</td>\n      <td>369.0</td>\n      <td>10055.0</td>\n      <td>119.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54</td>\n      <td>10300</td>\n      <td>12</td>\n      <td>3.0</td>\n      <td>8198.0</td>\n      <td>26.0</td>\n      <td>1.0</td>\n      <td>54.0</td>\n      <td>10055.0</td>\n      <td>31.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>10284</td>\n      <td>12</td>\n      <td>1.0</td>\n      <td>8198.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>10055.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>7827.0</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>7792.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6639289</th>\n      <td>45</td>\n      <td>18454</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>702.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>675.0</td>\n      <td>0.0</td>\n      <td>19.0</td>\n      <td>622.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>6639290</th>\n      <td>45</td>\n      <td>16188</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>702.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>6639291</th>\n      <td>45</td>\n      <td>15757</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>702.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>675.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>622.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>1251.0</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>6639292</th>\n      <td>45</td>\n      <td>19648</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>702.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>675.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>622.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>6639293</th>\n      <td>45</td>\n      <td>969</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>702.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>675.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>622.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>1251.0</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n<p>6639294 rows × 25 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"dates = all_data['date_block_num']\n\nlast_block = dates.max()\n#print(last_block)\n\nX_train = all_data.loc[dates < last_block - 1].drop(to_drop_cols, axis=1)\nX_cv = all_data.loc[dates ==  last_block - 1].drop(to_drop_cols, axis=1)\nX_test =  all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n\ny_train = all_data.loc[dates <  last_block - 1, 'target'].values\ny_cv = all_data.loc[dates ==  last_block - 1, 'target'].values\ny_test =  all_data.loc[dates == last_block, 'target'].values\n\n# print(X_train_part.shape)\n# print(y_train_part.shape)\n\n# X_train.to_pickle(\"X_train.pkl\")\n# X_train_part.to_pickle(\"X_train_part.pkl\")\n# X_test.to_pickle(\"X_test.pkl\")\n\n# np.save(\"y_train.npy\", y_train)\n# np.save(\"y_train_part.npy\", y_train_part)\n# np.save(\"y_test.npy\", y_test)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lgbm_train(X_train,y_train,X_test,y_test,num_iter):\n    lgb_params = {\n                   'feature_fraction': 0.75,\n                   'metric': 'rmse',\n                   'nthread':1, \n                   'min_data_in_leaf': 2**7, \n                   'bagging_fraction': 0.75, \n                   'learning_rate': 0.03, \n                   'objective': 'mse', \n                   'bagging_seed': 2**7, \n                   'num_leaves': 2**7,\n                   'bagging_freq':1,\n                   'verbose':0 \n                  }\n\n    evals_result = {}\n    \n    lgb_train = lgb.Dataset(X_train, label=y_train)\n    lgb_valid = lgb.Dataset(X_test, label=y_test)\n    model = lgb.train(lgb_params, lgb_train, num_iter,\n                      valid_sets=[lgb_train, lgb_valid],\n                      evals_result=evals_result,\n                      verbose_eval=10)\n    return model,evals_result\n","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y_train.clip(0,40)\n\nprint(X_train_part.shape)\nprint(y_train_part.shape)\nmodel,evals_result  = lgbm_train(X_train, y_train, X_cv, y_cv, 200)","execution_count":33,"outputs":[{"output_type":"stream","text":"(6186922, 21)\n(6186922,)\n[10]\ttraining's rmse: 1.28027\tvalid_1's rmse: 5.27475\n[20]\ttraining's rmse: 1.17893\tvalid_1's rmse: 5.22955\n[30]\ttraining's rmse: 1.11709\tvalid_1's rmse: 5.2001\n[40]\ttraining's rmse: 1.07662\tvalid_1's rmse: 5.18031\n[50]\ttraining's rmse: 1.05003\tvalid_1's rmse: 5.16596\n[60]\ttraining's rmse: 1.03286\tvalid_1's rmse: 5.15535\n[70]\ttraining's rmse: 1.01999\tvalid_1's rmse: 5.14819\n[80]\ttraining's rmse: 1.01057\tvalid_1's rmse: 5.14247\n[90]\ttraining's rmse: 1.00314\tvalid_1's rmse: 5.13792\n[100]\ttraining's rmse: 0.996975\tvalid_1's rmse: 5.13465\n[110]\ttraining's rmse: 0.992325\tvalid_1's rmse: 5.13214\n[120]\ttraining's rmse: 0.987735\tvalid_1's rmse: 5.1306\n[130]\ttraining's rmse: 0.98342\tvalid_1's rmse: 5.12956\n[140]\ttraining's rmse: 0.979181\tvalid_1's rmse: 5.1278\n[150]\ttraining's rmse: 0.975536\tvalid_1's rmse: 5.12724\n[160]\ttraining's rmse: 0.972245\tvalid_1's rmse: 5.12676\n[170]\ttraining's rmse: 0.969744\tvalid_1's rmse: 5.12598\n[180]\ttraining's rmse: 0.967444\tvalid_1's rmse: 5.12561\n[190]\ttraining's rmse: 0.965156\tvalid_1's rmse: 5.12489\n[200]\ttraining's rmse: 0.963201\tvalid_1's rmse: 5.12405\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_model('lgbm_model.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lgb.Booster(model_file='/kaggle/input/predict-future-sales/lgbm_model.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#linear regression in preparation for ensembling\nlr = LinearRegression()\ny_train = y_train.clip(0,40)\n\nlr.fit(X_train.values, y_train)\n# print(X_test.shape)\n# print(y_test.shape)\npred_lr = lr.predict(X_cv)\n\nprint('Test RMSE for linreg is %f' % np.sqrt(mean_squared_error(y_cv, pred_lr)))","execution_count":43,"outputs":[{"output_type":"stream","text":"Test RMSE for linreg is 1.042512\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lgb = model.predict(X_cv)\npred_lr = pred_lr.clip(0,40)\npred_lgb = pred_lgb.clip(0,40)\nX_cv_level2 = np.c_[pred_lr, pred_lgb]\nnp.save(\"X_cv_level2.npy\", X_cv_level2)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndates_train = dates[dates <  last_block - 1]\ndates_train_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n\n# That is how we get target for the 2nd level dataset\ny_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n\n# And here we create 2nd level feeature matrix, init it with zeros first\nX_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n\ncount = 0\n# Now fill `X_train_level2` with metafeatures\nfor cur_block_num in [27, 28, 29, 30, 31, 32]:\n    \n    print(cur_block_num)\n    \n    '''\n        1. Split `X_train` into parts\n           Remember, that corresponding dates are stored in `dates_train` \n        2. Fit linear regression \n        3. Fit LightGBM and put predictions          \n        4. Store predictions from 2. and 3. in the right place of `X_train_level2`. \n           You can use `dates_train_level2` for it\n           Make sure the order of the meta-features is the same as in `X_test_level2`\n    '''\n    X_train_cur = X_train[dates_train.isin(range(12,cur_block_num))]\n    y_train_cur = y_train[dates_train.isin(range(12,cur_block_num))]\n    X_test_cur = X_train[dates_train.isin([cur_block_num])]\n    \n    lr.fit(X_train_cur.values, y_train_cur)\n    pred_lr = lr.predict(X_test_cur.values)\n    \n    model_temp,_ = lgbm_train(X_train_cur, y_train_cur, X_train_cur, y_train_cur, 200)\n    pred_lgb = model_temp.predict(X_test_cur)\n    \n    for i in range(len(pred_lr)):\n        X_train_level2[count+i][0]=pred_lr[i]\n        X_train_level2[count+i][1]=pred_lgb[i]\n    count+=len(pred_lr)\nnp.save(\"X_train_full_level2.npy\", X_train_level2)\nnp.save(\"y_train_full_level2.npy\", y_train_level2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_level2 = np.load(\"X_train_full_level2.npy\")\ny_train_level2 = np.load(\"y_train_full_level2.npy\")\n\nlr.fit(X_train_level2, y_train_level2)\n\ntest_preds = lr.predict(X_cv_level2)\nrmse_test_stacking = np.sqrt(mean_squared_error(y_cv, test_preds))\nrmse_test_stacking","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"1.0064872972254926"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_lgb_test = model.predict(X_test)\npred_ens_test = best_alpha*pred_lgb_test + (1-best_alpha)*pred_lr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop_cols = ['ID','date_block_num']\nX_test_final =  test_data.drop(to_drop_cols, axis=1)\npred_lgb_final = model_full.predict(X_test_final)\n# pred_lr_final = lr_full.predict(X_test_final)\n#pred_ens = best_alpha*pred_lgb_final + (1-best_alpha)*pred_lr_final\n#print(pred_lgb)\n\nmerged = test.copy()\nmerged['item_cnt_month'] = pred_lgb_final\nmerged['item_cnt_month']=merged['item_cnt_month'].clip(lower=0,upper=20)\nmerged=merged.drop(['shop_id','item_id'],axis=1)\nmerged['ID']=merged['ID'].astype('int')\nmerged.to_csv(\"lightgbm_clipto40.csv\",index=False)\nprint(merged.head)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}